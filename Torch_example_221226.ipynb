{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759703e4",
   "metadata": {},
   "source": [
    "# 1D Tensor (221226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63fd6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conda install pytorch torchvision torchaudio -c pytorch\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([0, 1, 2, 3, 4])\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8058821a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e179369c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea50620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서 차원 변경하기\n",
    "\n",
    "a_col = a.view(5,1)\n",
    "a_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eee900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_col = a.view(-1,1)\n",
    "a_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd7ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch 텐서를 Numpy로 변환하기 --> 기존의 판다스나 그래프 작업 등 가능\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "numpy_array = np.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "back_to_numpy = torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd95b74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5.], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b43d42a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbee82f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1000,  2.0000,  0.3000, 10.1000], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas Series -> Torch Tensor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pandas_series = pd.Series([0.1, 2, 0.3, 10.1])\n",
    "pandas_to_torch = torch.from_numpy(pandas_series.values)  #.values\n",
    "pandas_to_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4c5417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스처럼 사용가능\n",
    "\n",
    "new_tensor = torch.tensor([5, 2, 6, 1])\n",
    "new_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb9f36c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "673f07cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3951ee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2952e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20,  1,  3, 11,  1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱싱, 슬라이싱\n",
    "\n",
    "c = torch.tensor([20, 1, 3, 11, 1])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57b1c81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100,   1,   3,  11,   1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]=100\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90ff2199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  3, 11])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c[1:4]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b942a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[3:5] = torch.tensor([300, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "716719c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100,   1,   3, 300, 400])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b51b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [8]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# product of 2 tensor\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = torch.tensor([3, 4])\n",
    "\n",
    "u_ = u.view(-1, 1)\n",
    "v_ = v.view(-1, 1)\n",
    "\n",
    "z = u_*v_\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2e113a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = u*v\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ece3c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot Product\n",
    "\n",
    "z = torch.dot(u, v)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a4224b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m z\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "source": [
    "z = torch.dot(u_, v_)\n",
    "z\n",
    "\n",
    "# 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2db000ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting : 모든 원소에 1을 더한다.\n",
    "\n",
    "z = u+1\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bec7ac04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0399ee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# universal functions\n",
    "\n",
    "a = torch.tensor([1, -1, 1, -1])\n",
    "max_a = a.max()\n",
    "max_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d7267cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(-2, 2, steps =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007a4da",
   "metadata": {},
   "source": [
    "# 2D Tensor (221227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d12a60eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1,2], [2,3], [4,5]])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf147aec",
   "metadata": {},
   "source": [
    "## Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22a17e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad478777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b012a1",
   "metadata": {},
   "source": [
    "### dot product: AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5251445c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "B = torch.tensor([[1, 1], [1, 1], [-1, 1]])\n",
    "C = torch.mm(A, B)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01ca3fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11,  3],\n",
       "        [33,  3],\n",
       "        [22,  2]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A':[11, 33, 22],'B':[3, 3, 2]})\n",
    "torch.tensor(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4717e98",
   "metadata": {},
   "source": [
    "### Differentiation in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "392fc3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y(x) = x^2\n",
    "# y(x=2) = 2^2\n",
    "\n",
    "# 2로 입력하면 에러 발생, 2.0으로 입력해야 (221227)\n",
    "# RuntimeError: Only Tensors of floating point and complex dtype can require gradients\n",
    "\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "external_grad = torch.tensor(1.)    # 문법적인 방법 (221227)\n",
    "y.backward(gradient=external_grad)\n",
    "#y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "674e4830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eaf19e",
   "metadata": {},
   "source": [
    "### Partial Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c97d5d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 18.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = 3*a**2 - b**2\n",
    "\n",
    "external_grad = torch.tensor([1., 1.])   # [1., 1.] 값의 의미?\n",
    "Q.backward(gradient=external_grad)\n",
    "\n",
    "a.grad   # a 편미분 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7208b8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  -8.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d14421f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor(1., requires_grad=True)\n",
    "v = torch.tensor(2., requires_grad=True)\n",
    "\n",
    "f = u*v + u**2\n",
    "\n",
    "f.backward()\n",
    "\n",
    "v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9e593e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.grad   # v+2u = 2+2(1) = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06481811",
   "metadata": {},
   "source": [
    "# Simple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Data Set Class and Object\n",
    "# build a Data Set Transform\n",
    "# Compose Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea91d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# Define class for dataset\n",
    "\n",
    "class toy_set(Dataset):\n",
    "    \n",
    "    # Constructor with defult values \n",
    "    def __init__(self, length = 100, transform = None):\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "     \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4a1bf9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 토이 데이터셋 클래스\n",
    "\n",
    "class toy_set(Dataset):\n",
    "    def __init__(self, length=100, transform=None):\n",
    "        \n",
    "        self.x = 2*torch.ones(length, 2)   # self.x => [2, 2], [2, 2] .....\n",
    "        self.y = torch.ones(length, 1)     # self.y => 2, 2, 2, ...\n",
    "        self.len = length                  # index => 0, 1, 2, ...\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample=self.x[index], self.y[index]   # 텐서 x, y를 sample 에 저장\n",
    "        \n",
    "        if self.transform:\n",
    "            sample=self.transform(sample)  \n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7f2178bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = toy_set()\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23322f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2.]), tensor([1.]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab120bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2.]), tensor([1.]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "98664ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x: tensor([2., 2.]) y: tensor([1.])\n",
      "1 x: tensor([2., 2.]) y: tensor([1.])\n",
      "2 x: tensor([2., 2.]) y: tensor([1.])\n",
      "3 x: tensor([2., 2.]) y: tensor([1.])\n",
      "4 x: tensor([2., 2.]) y: tensor([1.])\n",
      "5 x: tensor([2., 2.]) y: tensor([1.])\n",
      "6 x: tensor([2., 2.]) y: tensor([1.])\n",
      "7 x: tensor([2., 2.]) y: tensor([1.])\n",
      "8 x: tensor([2., 2.]) y: tensor([1.])\n",
      "9 x: tensor([2., 2.]) y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x, y = dataset[i]\n",
    "    print(i, 'x:', x, 'y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71064a87",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a74ef845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_mult(object):\n",
    "    \n",
    "    def __init__(self, addx=1, muly=1):  # x에 더해질 숫자, y에 곱해질 숫자 미리 선언\n",
    "        self.addx=addx\n",
    "        self.muly=muly\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        x=sample[0]\n",
    "        y=sample[1]\n",
    "        x=x+self.addx\n",
    "        y=y*self.muly\n",
    "        \n",
    "        sample=x,y   # 각각 계산된 x, y를 sample에 전달\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a3a72884",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=toy_set() # Transform 파라미터가 없이 선언 (None) -->  self.transform = None\n",
    "\n",
    "# 단순히 텐서 x와 텐서 y를 얻는다  ---> return sample\n",
    "\n",
    "a_m=add_mult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7bddcec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번때 데이터셋을 a_m 오브젝트에 \n",
    "\n",
    "x_, y_ = a_m(dataset[0])\n",
    "\n",
    "# dataset[0] : ([2,2], 1)  ---> 튜플을 전달\n",
    "# x: [2, 2] +1 => [3, 3]\n",
    "# y: 1*1 => 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee7d1c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bab9eb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2f46e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform 오브젝트를 적용하면,\n",
    "\n",
    "dataset_ = toy_set(transform=a_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c706cf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 3.]), tensor([1.]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 간단히 동일한 결과를 얻을 수 있다. (221228)\n",
    "\n",
    "dataset_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ca3dc",
   "metadata": {},
   "source": [
    "# transforms, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Data Set Class and Object\n",
    "# Build a Data Set Transform\n",
    "# Compose Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bbe13",
   "metadata": {},
   "source": [
    "### Transforms compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기 정의된 2개의 클래스\n",
    "# add_mult  : 더하기, 곱하기\n",
    "# mult : 곱하기만\n",
    "\n",
    "# 컨스트럭터를 리스트로 입력한다.\n",
    "\n",
    "'''\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "data_transform = transforms.Compose([add_mult(), mult()])\n",
    "\n",
    "x_, y_ = data_transform(dataset[0]) \n",
    "\n",
    "# add_mult() -> mult() 순으로 순차적으로 계산하여 output 출력\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토이 셋에 data_transform 을 바로 적용할 수 있다.\n",
    "\n",
    "'''\n",
    "\n",
    "data_set_tr = toy_set(transform=data_transform)\n",
    "\n",
    "data_set_tr[0]   # 출력 값을 확인\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5378101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tranform class mult\n",
    "\n",
    "class mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, mult = 100):\n",
    "        self.mult = mult\n",
    "        \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d6702818",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PILLOW_VERSION' from 'PIL' (/Users/wontaelee/miniforge3/lib/python3.9/site-packages/PIL/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      3\u001b[0m data_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([add_mult(), mult()])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torchvision/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torchvision/datasets/__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvhn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVHN\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphototour\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PhotoTour\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfakedata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeData\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msemeion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SEMEION\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01momniglot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Omniglot\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torchvision/datasets/fakedata.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFakeData\u001b[39;00m(data\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124;03m\"\"\"A fake dataset that returns randomly generated images and returns them as PIL images\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torchvision/transforms/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torchvision/transforms/transforms.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     20\u001b[0m     Sequence \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mSequence\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torchvision/transforms/functional.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps, ImageEnhance, PILLOW_VERSION\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maccimage\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PILLOW_VERSION' from 'PIL' (/Users/wontaelee/miniforge3/lib/python3.9/site-packages/PIL/__init__.py)"
     ]
    }
   ],
   "source": [
    "# torchvision 설치 방법? (221227)\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "data_transform = transforms.Compose([add_mult(), mult()])\n",
    "\n",
    "# 기 계산 결과에서 x, y 각각에 100을 곱한 값을 출력하는지 확인 (221228)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c94beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[base]",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
